{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 02 - Train Base Classifier\n",
    "\n",
    "Goals:\n",
    "1. Load data with configurable subset size\n",
    "2. Create PyTorch DataLoaders with proper transforms\n",
    "3. Train ResNet-50 for multi-label classification\n",
    "4. Evaluate and validate F1 ≥ 0.40\n",
    "5. Generate and save predictions for conformal methods\n",
    "\n",
    "This notebook uses MPS acceleration for M3 Pro."
   ],
   "id": "f4785b3a97651f39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "# Add src to path\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from config import CONFIG, LABELS, DATA_DIR, MODELS_DIR, RESULTS_DIR, print_config\n",
    "\n",
    "# Print configuration\n",
    "print_config()"
   ],
   "id": "d5bc7dae5a23bf07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set seeds for reproducibility\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # MPS doesn't have manual_seed but setting torch seed covers it\n",
    "\n",
    "set_seed(CONFIG[\"seed\"])\n",
    "print(f\"Random seed set to: {CONFIG['seed']}\")"
   ],
   "id": "4b6693fa70c2ff0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting up device\n",
    "\n",
    "device = CONFIG[\"device\"]\n",
    "\n",
    "# Verify MPS is available\n",
    "if device == \"mps\":\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS (Metal Performance Shaders) is available\")\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        print(\"MPS not available, falling back to CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "elif device == \"cuda\":\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA is available: {torch.cuda.get_device_name(0)}\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"CUDA not available, falling back to CPU\")\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ],
   "id": "3e7e333d0cd950fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load metadata\n",
    "\n",
    "print(\"Loading metadata...\")\n",
    "metadata_path = DATA_DIR / \"metadata_with_splits.csv\"\n",
    "df = pd.read_csv(metadata_path)\n",
    "print(f\"Total images in metadata: {len(df):,}\")\n",
    "\n",
    "# Load Kaggle path for images\n",
    "kaggle_path_file = DATA_DIR / \"kaggle_path.txt\"\n",
    "with open(kaggle_path_file, 'r') as f:\n",
    "    KAGGLE_PATH = Path(f.read().strip())\n",
    "print(f\"Images location: {KAGGLE_PATH}\")"
   ],
   "id": "de4da2952a9eea13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply subset if configured\n",
    "\n",
    "subset_size = CONFIG[\"subset_size\"]\n",
    "\n",
    "if subset_size is not None and subset_size < len(df):\n",
    "    print(f\"\\nApplying subset: {subset_size:,} images\")\n",
    "\n",
    "    # Sample proportionally from each split to maintain ratios\n",
    "    df_subset = []\n",
    "    for split in ['train', 'val', 'cal', 'test']:\n",
    "        split_df = df[df['split'] == split]\n",
    "        ratio = {'train': 0.70, 'val': 0.10, 'cal': 0.10, 'test': 0.10}[split]\n",
    "        n_samples = int(subset_size * ratio)\n",
    "\n",
    "        # Sample by patient to avoid data leakage\n",
    "        patients = split_df['Patient ID'].unique()\n",
    "        np.random.shuffle(patients)\n",
    "\n",
    "        # Take patients until we have enough images\n",
    "        selected_patients = []\n",
    "        count = 0\n",
    "        for p in patients:\n",
    "            patient_images = len(split_df[split_df['Patient ID'] == p])\n",
    "            if count + patient_images <= n_samples * 1.2:  # Allow 20% margin\n",
    "                selected_patients.append(p)\n",
    "                count += patient_images\n",
    "            if count >= n_samples:\n",
    "                break\n",
    "\n",
    "        split_subset = split_df[split_df['Patient ID'].isin(selected_patients)]\n",
    "        df_subset.append(split_subset)\n",
    "\n",
    "    df = pd.concat(df_subset, ignore_index=True)\n",
    "    print(f\"Subset created: {len(df):,} images\")\n",
    "\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df['split'].value_counts())"
   ],
   "id": "e24031553bdb68f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter to only images with at least one disease\n",
    "print(\"\\nFiltering to images with at least one disease label...\")\n",
    "\n",
    "def has_disease(finding_labels_str):\n",
    "    \"\"\"Check if image has at least one of our 14 diseases\"\"\"\n",
    "    findings = finding_labels_str.split(\"|\")\n",
    "    for finding in findings:\n",
    "        if finding in LABELS:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Count before filtering\n",
    "total_before = len(df)\n",
    "no_finding_count = (~df['Finding Labels'].apply(has_disease)).sum()\n",
    "\n",
    "# Filter\n",
    "df = df[df['Finding Labels'].apply(has_disease)].reset_index(drop=True)\n",
    "\n",
    "print(f\"  Before filtering: {total_before:,} images\")\n",
    "print(f\"  'No Finding' removed: {no_finding_count:,} images\")\n",
    "print(f\"  After filtering: {len(df):,} images with diseases\")\n",
    "\n",
    "print(f\"\\nNew split distribution:\")\n",
    "print(df['split'].value_counts())\n",
    "\n",
    "# Verify positive label rate improved\n",
    "sample_labels = np.array([\n",
    "    [1 if l in row.split(\"|\") else 0 for l in LABELS]\n",
    "    for row in df['Finding Labels'].head(1000)\n",
    "])\n",
    "new_positive_rate = sample_labels.mean() * 100\n",
    "print(f\"\\nPositive label rate (sample): {new_positive_rate:.1f}%\")"
   ],
   "id": "e39ee2ce3e7c3d37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define dataset class\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ChestX-ray14 Dataset for multi-label classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, image_root, labels, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.image_root = Path(image_root)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        # Find image directories (images are in subfolders)\n",
    "        self.image_dirs = list(self.image_root.glob(\"images_*/images\"))\n",
    "        if not self.image_dirs:\n",
    "            # Try direct path\n",
    "            self.image_dirs = [self.image_root]\n",
    "\n",
    "        print(f\"Image directories found: {len(self.image_dirs)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        image_name = row['Image Index']\n",
    "        image_path = self._find_image(image_name)\n",
    "\n",
    "        if image_path is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {image_name}\")\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Parse labels\n",
    "        labels = self._parse_labels(row['Finding Labels'])\n",
    "        labels = torch.from_numpy(labels)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "    def _find_image(self, image_name):\n",
    "        \"\"\"Search for image in all image directories\"\"\"\n",
    "        for img_dir in self.image_dirs:\n",
    "            img_path = img_dir / image_name\n",
    "            if img_path.exists():\n",
    "                return img_path\n",
    "        return None\n",
    "\n",
    "    def _parse_labels(self, finding_labels_str):\n",
    "        \"\"\"Convert label string to binary vector\"\"\"\n",
    "        findings = finding_labels_str.split(\"|\")\n",
    "        binary = np.zeros(len(self.labels), dtype=np.float32)\n",
    "        for finding in findings:\n",
    "            if finding in self.labels:\n",
    "                idx = self.labels.index(finding)\n",
    "                binary[idx] = 1.0\n",
    "        return binary"
   ],
   "id": "b9dbff1bcd841338",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define transforms\n",
    "\n",
    "image_size = CONFIG[\"image_size\"]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(f\"Image size: {image_size}x{image_size}\")\n",
    "print(f\"Train augmentations: flip, rotation, affine\")"
   ],
   "id": "6f5709fc4b152dc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create datasets and dataloaders\n",
    "\n",
    "print(\"\\nCreating datasets...\")\n",
    "\n",
    "train_df = df[df['split'] == 'train']\n",
    "val_df = df[df['split'] == 'val']\n",
    "cal_df = df[df['split'] == 'cal']\n",
    "test_df = df[df['split'] == 'test']\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_df, KAGGLE_PATH, LABELS, transform=train_transform)\n",
    "val_dataset = ChestXrayDataset(val_df, KAGGLE_PATH, LABELS, transform=eval_transform)\n",
    "cal_dataset = ChestXrayDataset(cal_df, KAGGLE_PATH, LABELS, transform=eval_transform)\n",
    "test_dataset = ChestXrayDataset(test_df, KAGGLE_PATH, LABELS, transform=eval_transform)\n",
    "\n",
    "print(f\"Train: {len(train_dataset):,} images\")\n",
    "print(f\"Val:   {len(val_dataset):,} images\")\n",
    "print(f\"Cal:   {len(cal_dataset):,} images\")\n",
    "print(f\"Test:  {len(test_dataset):,} images\")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = CONFIG[\"batch_size\"]\n",
    "num_workers = 0\n",
    "pin_memory = False\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=num_workers, pin_memory=pin_memory)\n",
    "cal_loader = DataLoader(cal_dataset, batch_size=batch_size, shuffle=False,\n",
    "                        num_workers=num_workers, pin_memory=pin_memory)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "print(f\"\\nBatch size: {batch_size}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")"
   ],
   "id": "9bcb48fd2c33281c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test data loading\n",
    "\n",
    "print(\"\\nTesting data loading...\")\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Label batch shape: {labels.shape}\")\n",
    "print(f\"Label example: {labels[0].numpy()}\")\n",
    "print(f\"Active labels: {[LABELS[i] for i in torch.where(labels[0] == 1)[0].tolist()]}\")"
   ],
   "id": "a99be725fa97c1ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "\n",
    "class ChestXrayClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-50 based multi-label classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=14, dropout=0.5, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load pretrained ResNet-50\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None\n",
    "        self.backbone = models.resnet50(weights=weights)\n",
    "\n",
    "        # Get feature dimension\n",
    "        num_features = self.backbone.fc.in_features\n",
    "\n",
    "        # Replace final layer with custom head\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_features, num_classes),\n",
    "            nn.Sigmoid()  # Multi-label: independent probabilities\n",
    "        )\n",
    "\n",
    "        # Track which layers are frozen\n",
    "        self.backbone_frozen = False\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze all backbone parameters\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.backbone_frozen = True\n",
    "        print(\"Backbone frozen\")\n",
    "\n",
    "    def unfreeze_backbone(self, layers=['layer3', 'layer4']):\n",
    "        \"\"\"Unfreeze specific backbone layers\"\"\"\n",
    "        for name, module in self.backbone.named_children():\n",
    "            if name in layers:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "                print(f\"Unfroze: {name}\")\n",
    "        self.backbone_frozen = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# Create model\n",
    "model = ChestXrayClassifier(\n",
    "    num_classes=len(LABELS),\n",
    "    dropout=CONFIG[\"dropout\"],\n",
    "    pretrained=CONFIG[\"pretrained\"]\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel: ResNet-50\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ],
   "id": "a48a7bd642471a0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define loss function with class weights\n",
    "\n",
    "def compute_class_weights(dataloader, num_classes):\n",
    "    \"\"\"Compute class weights for imbalanced dataset\"\"\"\n",
    "    label_counts = torch.zeros(num_classes)\n",
    "    total_samples = 0\n",
    "\n",
    "    for _, labels in tqdm(dataloader, desc=\"Computing class weights\"):\n",
    "        label_counts += labels.sum(dim=0)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Weight = total / (2 * count), capped for rare classes\n",
    "    weights = total_samples / (2 * (label_counts + 1))\n",
    "    weights = torch.clamp(weights, min=0.5, max=10.0)  # Prevent extreme weights\n",
    "\n",
    "    return weights\n",
    "\n",
    "print(\"Computing class weights...\")\n",
    "class_weights = compute_class_weights(train_loader, len(LABELS))\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(\"\\nClass weights:\")\n",
    "for i, (label, weight) in enumerate(zip(LABELS, class_weights)):\n",
    "    print(f\"  {label}: {weight:.2f}\")"
   ],
   "id": "d5fd77ba580fc011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define weighted BCE loss\n",
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Binary cross-entropy with class weights\n",
    "        bce = -(\n",
    "            targets * torch.log(predictions + 1e-7) * self.weights +\n",
    "            (1 - targets) * torch.log(1 - predictions + 1e-7)\n",
    "        )\n",
    "        return bce.mean()\n",
    "\n",
    "criterion = WeightedBCELoss(class_weights)"
   ],
   "id": "abc3e7764d8e35d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define training functions\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device, grad_clip=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Evaluating\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    return total_loss / len(loader), all_preds, all_labels\n",
    "\n",
    "\n",
    "def compute_metrics(predictions, labels, threshold=0.5):\n",
    "    \"\"\"Compute multi-label classification metrics\"\"\"\n",
    "    preds_binary = (predictions > threshold).float()\n",
    "\n",
    "    # Per-label metrics\n",
    "    f1_scores = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for k in range(labels.shape[1]):\n",
    "        tp = ((preds_binary[:, k] == 1) & (labels[:, k] == 1)).sum().item()\n",
    "        fp = ((preds_binary[:, k] == 1) & (labels[:, k] == 0)).sum().item()\n",
    "        fn = ((preds_binary[:, k] == 0) & (labels[:, k] == 1)).sum().item()\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-7)\n",
    "        recall = tp / (tp + fn + 1e-7)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        'macro_f1': np.mean(f1_scores),\n",
    "        'macro_precision': np.mean(precisions),\n",
    "        'macro_recall': np.mean(recalls),\n",
    "        'per_label_f1': f1_scores\n",
    "    }"
   ],
   "id": "f5bbb46bf9290e9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Phase 1: Train head only\n",
    "print(\"\\n--- Phase 1: Training classification head (backbone frozen) ---\")\n",
    "model.freeze_backbone()\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=CONFIG[\"phase1_lr\"],\n",
    "    weight_decay=CONFIG[\"weight_decay\"]\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "\n",
    "best_f1 = 0.0\n",
    "patience_counter = 0\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_f1': []}\n",
    "\n",
    "for epoch in range(CONFIG[\"phase1_epochs\"]):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['phase1_epochs']}\")\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device,\n",
    "                             CONFIG[\"gradient_clip_norm\"])\n",
    "    val_loss, val_preds, val_labels = evaluate(model, val_loader, criterion, device)\n",
    "    metrics = compute_metrics(val_preds, val_labels)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_f1'].append(metrics['macro_f1'])\n",
    "\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val F1:     {metrics['macro_f1']:.4f}\")\n",
    "\n",
    "    if metrics['macro_f1'] > best_f1:\n",
    "        best_f1 = metrics['macro_f1']\n",
    "        torch.save(model.state_dict(), MODELS_DIR / \"best_model.pth\")\n",
    "        patience_counter = 0\n",
    "        print(f\"  ✓ New best model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CONFIG[\"early_stopping_patience\"]:\n",
    "            print(f\"  Early stopping triggered!\")\n",
    "            break"
   ],
   "id": "fb5823c06b7f2eb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fine-tune backbone\n",
    "\n",
    "print(\"\\n--- Phase 2: Fine-tuning backbone layers 3-4 ---\")\n",
    "model.load_state_dict(torch.load(MODELS_DIR / \"best_model.pth\"))\n",
    "model.unfreeze_backbone(['layer3', 'layer4'])\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=CONFIG[\"phase2_lr\"],\n",
    "    weight_decay=CONFIG[\"weight_decay\"]\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)\n",
    "\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(CONFIG[\"phase2_epochs\"]):\n",
    "    print(f\"\\nEpoch {CONFIG['phase1_epochs'] + epoch + 1}/{CONFIG['phase1_epochs'] + CONFIG['phase2_epochs']}\")\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device,\n",
    "                             CONFIG[\"gradient_clip_norm\"])\n",
    "    val_loss, val_preds, val_labels = evaluate(model, val_loader, criterion, device)\n",
    "    metrics = compute_metrics(val_preds, val_labels)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_f1'].append(metrics['macro_f1'])\n",
    "\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val F1:     {metrics['macro_f1']:.4f}\")\n",
    "\n",
    "    if metrics['macro_f1'] > best_f1:\n",
    "        best_f1 = metrics['macro_f1']\n",
    "        torch.save(model.state_dict(), MODELS_DIR / \"best_model.pth\")\n",
    "        patience_counter = 0\n",
    "        print(f\"  ✓ New best model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CONFIG[\"early_stopping_patience\"]:\n",
    "            print(f\"  Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n✓ Training complete! Best F1: {best_f1:.4f}\")"
   ],
   "id": "a6f8c0053b3b5e2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot training history\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history['train_loss'], label='Train', marker='o')\n",
    "ax1.plot(history['val_loss'], label='Val', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training & Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# F1 plot\n",
    "ax2 = axes[1]\n",
    "ax2.plot(history['val_f1'], label='Val F1', marker='o', color='green')\n",
    "ax2.axhline(y=CONFIG[\"acceptable_f1\"], color='red', linestyle='--',\n",
    "            label=f'Target F1 ({CONFIG[\"acceptable_f1\"]})')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Macro F1')\n",
    "ax2.set_title('Validation F1 Score')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / \"figures\" / \"training_history.png\", dpi=150)\n",
    "plt.show()"
   ],
   "id": "2e369b2ad7a177ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Final evaluation on test set\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(MODELS_DIR / \"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_preds, test_labels = evaluate(model, test_loader, criterion, device)\n",
    "test_metrics = compute_metrics(test_preds, test_labels)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss:      {test_loss:.4f}\")\n",
    "print(f\"  Macro F1:  {test_metrics['macro_f1']:.4f}\")\n",
    "print(f\"  Precision: {test_metrics['macro_precision']:.4f}\")\n",
    "print(f\"  Recall:    {test_metrics['macro_recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-Label F1 Scores:\")\n",
    "for label, f1 in zip(LABELS, test_metrics['per_label_f1']):\n",
    "    print(f\"  {label:<20}: {f1:.4f}\")\n",
    "\n",
    "# Check if acceptable\n",
    "if test_metrics['macro_f1'] >= CONFIG[\"acceptable_f1\"]:\n",
    "    print(f\"\\n✓ F1 score ({test_metrics['macro_f1']:.4f}) meets target ({CONFIG['acceptable_f1']})\")\n",
    "else:\n",
    "    print(f\"\\n✗ F1 score ({test_metrics['macro_f1']:.4f}) below target ({CONFIG['acceptable_f1']})\")\n",
    "    print(\"  Consider: more epochs, larger subset, or hyperparameter tuning\")"
   ],
   "id": "c14fc8047bf2c663",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate predictions for conformal methods\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING PREDICTIONS FOR CONFORMAL METHODS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Generating predictions\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "    return np.vstack(all_preds), np.vstack(all_labels)\n",
    "\n",
    "# Generate predictions for all splits\n",
    "print(\"\\nTrain set...\")\n",
    "train_preds, train_labels = get_predictions(model, train_loader, device)\n",
    "\n",
    "print(\"Calibration set...\")\n",
    "cal_preds, cal_labels = get_predictions(model, cal_loader, device)\n",
    "\n",
    "print(\"Test set...\")\n",
    "test_preds, test_labels_np = get_predictions(model, test_loader, device)\n",
    "\n",
    "print(f\"\\nPrediction shapes:\")\n",
    "print(f\"  Train: {train_preds.shape}\")\n",
    "print(f\"  Cal:   {cal_preds.shape}\")\n",
    "print(f\"  Test:  {test_preds.shape}\")"
   ],
   "id": "f8e202d28af3b61e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save predictions\n",
    "\n",
    "print(\"\\nSaving predictions...\")\n",
    "\n",
    "predictions_dir = RESULTS_DIR / \"predictions\"\n",
    "predictions_dir.mkdir(exist_ok=True)\n",
    "\n",
    "np.save(predictions_dir / \"train_preds.npy\", train_preds)\n",
    "np.save(predictions_dir / \"train_labels.npy\", train_labels)\n",
    "np.save(predictions_dir / \"cal_preds.npy\", cal_preds)\n",
    "np.save(predictions_dir / \"cal_labels.npy\", cal_labels)\n",
    "np.save(predictions_dir / \"test_preds.npy\", test_preds)\n",
    "np.save(predictions_dir / \"test_labels.npy\", test_labels_np)\n",
    "\n",
    "print(f\"✓ Predictions saved to {predictions_dir}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_path = RESULTS_DIR / \"metrics\" / \"classifier_metrics.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'test_loss': float(test_loss),\n",
    "        'macro_f1': float(test_metrics['macro_f1']),\n",
    "        'macro_precision': float(test_metrics['macro_precision']),\n",
    "        'macro_recall': float(test_metrics['macro_recall']),\n",
    "        'per_label_f1': {label: float(f1) for label, f1 in zip(LABELS, test_metrics['per_label_f1'])},\n",
    "        'config': {k: str(v) if isinstance(v, Path) else v for k, v in CONFIG.items()},\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2)\n",
    "print(f\"✓ Metrics saved to {metrics_path}\")"
   ],
   "id": "9d69ec90d510f20c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "Model: ResNet-50 (pretrained on ImageNet)\n",
    "Dataset: ChestX-ray14 subset ({CONFIG['subset_size']} images)\n",
    "\n",
    "Final Test Metrics:\n",
    "  Macro F1:  {test_metrics['macro_f1']:.4f}\n",
    "  Precision: {test_metrics['macro_precision']:.4f}\n",
    "  Recall:    {test_metrics['macro_recall']:.4f}\n",
    "\n",
    "Files saved:\n",
    "  - {MODELS_DIR / 'best_model.pth'}\n",
    "  - {predictions_dir / 'train_preds.npy'}\n",
    "  - {predictions_dir / 'cal_preds.npy'}\n",
    "  - {predictions_dir / 'test_preds.npy'}\n",
    "  - {metrics_path}\n",
    "\n",
    "Next step: Run notebook 03_standard_conformal.ipynb\n",
    "\"\"\")"
   ],
   "id": "e6d00ab2696f8cdc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
